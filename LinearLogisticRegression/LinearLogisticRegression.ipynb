{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression \n",
    "\n",
    "This Jupyter Notebook accompanies the blog posts on Linear and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we will begin by importing the libraries we will need. \n",
    "__Numpy__ is a linear algebra library in Python and we will be using it to do all of the matrix and vector computations in our code.\n",
    "__Pandas__ is used to import our data and clean it up before we pass it to our machine learning algorithms.\n",
    "__Matplotlib__ will allow us to visualise the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to import the data - for linear regression. the dataset is on Housing Prices in Boston, sourced from Kaggle <a href=\"https://www.kaggle.com/c/boston-housing\"> here </a>. This explains which features the abbreviated columns look at. \n",
    "<br>\n",
    "For the purposes of the tutorial, we will split the train.csv file provided by Kaggle into our own train and test set, since the test.csv file doesn't have any labels.\n",
    "<br>**EXTENSION**: run the algorithms on the test.csv (provided in this repo) and submit your predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0   1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1   2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2   4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "3   5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "4   7  0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311   \n",
       "\n",
       "   ptratio   black  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     18.7  394.63   2.94  33.4  \n",
       "3     18.7  396.90   5.33  36.2  \n",
       "4     15.2  395.60  12.43  22.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset = pd.read_csv(\"boston-housing-dataset/train.csv\")\n",
    "house_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to clean up into the format we want:\n",
    "    X = _n x m_ matrix, Y = _1 x m _ matrix.\n",
    "<br> We can remove the ID column, since it is not a feature. We will shuffle the data, normalise it and then split it into train:test in an 80:20 split, and then separate the input features from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_dataset.drop(\"ID\", axis=1, inplace=True)\n",
    "house_dataset = house_dataset.reindex(np.random.permutation(house_dataset.index))\n",
    "\n",
    "#normalise the input features - this ensures they are all in the same range 0-1. \n",
    "house_dataset.loc[:, house_dataset.columns!=\"medv\"] -= house_dataset.loc[:, house_dataset.columns!=\"medv\"].mean()\n",
    "house_dataset.loc[:, house_dataset.columns!=\"medv\"] /= house_dataset.loc[:, house_dataset.columns!=\"medv\"].std()\n",
    "\n",
    "#transpose to get correct dimensions\n",
    "X_lin_train = house_dataset.loc[:house_dataset.shape[0]*4//5, house_dataset.columns!=\"medv\"].as_matrix().T \n",
    "Y_lin_train = house_dataset.loc[:house_dataset.shape[0]*4//5, [\"medv\"]].as_matrix().T\n",
    "\n",
    "X_lin_test = house_dataset.loc[house_dataset.shape[0]*4//5:, house_dataset.columns!=\"medv\"].as_matrix().T \n",
    "Y_lin_test = house_dataset.loc[house_dataset.shape[0]*4//5:, [\"medv\"]].as_matrix().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to load the breast cancer dataset - again this is from <a href=\"https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\">Kaggle</a> (though originally from UCI). To contrast with the other dataset, this dataset has features which seem hard to interpret on their own, unlike with housing prices where we can intuitively make sense of the features - e.g more rooms implies higher price. \n",
    "<br> This is where the power of machine learning comes in - to spot patterns in the data not possible by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_dataset = pd.read_csv(\"breast-cancer-dataset/data.csv\")\n",
    "cancer_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to clean up the data - remove the id, and convert the label from M/B to 1/0, as well as normalise the data and shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset.drop([\"id\",'Unnamed: 32'], axis=1, inplace=True)\n",
    "cancer_dataset[\"diagnosis\"] = cancer_dataset[\"diagnosis\"].apply(lambda x: 1 if (x==\"M\") else 0)\n",
    "\n",
    "#shuffle data\n",
    "cancer_dataset = cancer_dataset.reindex(np.random.permutation(cancer_dataset.index))\n",
    "\n",
    "#normalise the input features - this ensures they are all in the same range 0-1. \n",
    "cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"] -= cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"].mean()\n",
    "cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"] /= cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log_train = cancer_dataset.loc[:cancer_dataset.shape[0]*4//5, cancer_dataset.columns!=\"diagnosis\"].as_matrix().T \n",
    "Y_log_train = cancer_dataset.loc[:cancer_dataset.shape[0]*4//5, [\"diagnosis\"]].as_matrix().T \n",
    "\n",
    "X_log_test = cancer_dataset.loc[cancer_dataset.shape[0]*4//5:, cancer_dataset.columns!=\"diagnosis\"].as_matrix().T \n",
    "Y_log_test = cancer_dataset.loc[cancer_dataset.shape[0]*4//5:, [\"diagnosis\"]].as_matrix().T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialise the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_lin = np.random.randn(Y_lin_train.shape[0], X_lin_train.shape[0])\n",
    "b_lin = np.random.randn(Y_lin_train.shape[0],1)\n",
    "\n",
    "W_log = np.random.randn(Y_log_train.shape[0], X_log_train.shape[0])\n",
    "b_log = np.random.randn(Y_log_train.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 367)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_log_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we code up the equations for the forward step:\n",
    "    $$ \\hat{Y}_{lin} = WX+b$$\n",
    "    $$ \\hat{Y}_{log} = \\sigma(WX+b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_lin(X, W, b):\n",
    "    return np.dot(W,X)+b\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-z))\n",
    "\n",
    "def forward_log(X,W,b):\n",
    "    return sigmoid(forward_lin(X,W,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some sample predictions from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.150518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.5</td>\n",
       "      <td>2.665321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.1</td>\n",
       "      <td>2.376511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y  predictions\n",
       "0  50.0    -0.150518\n",
       "1  16.5     2.665321\n",
       "2  19.1     2.376511"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"predictions\":forward_lin(X_lin_train[:,:3],W_lin,b_lin)[0] , \"Y\": Y_lin_train[:,:3][0] }).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.933207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.215260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  predictions\n",
       "0  0     0.998004\n",
       "1  0     0.933207\n",
       "2  0     0.995197\n",
       "3  0     0.215260\n",
       "4  0     0.994377"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"predictions\":forward_log(X_log_train[:,:5],W_log,b_log)[0] , \"Y\": Y_log_train[:,:5][0] }).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very good! So let's train the model:\n",
    "\n",
    "First - the loss functions need to be defined: these are\n",
    "\n",
    "$$ J(W,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (y^{(i)}_{pred} - y^{(i)})^2 $$\n",
    "\n",
    "\n",
    "$$ J(W,b) = \\frac{-1}{m} \\sum_{i=1}^{m} y^{(i)} \\log(y^{(i)}_{pred}) + (1-y^{(i)}) \\log(1-y^{(i)}_{pred})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(Y, Y_pred):\n",
    "    return (1.0/(2*Y.shape[1]))*np.sum(np.square(Y-Y_pred))\n",
    "                                      \n",
    "\n",
    "def log_loss(Y, Y_pred):\n",
    "    return (-1.0/(Y.shape[1]))*np.sum(Y*np.log(Y_pred) + (1-Y)*np.log(1-Y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342.3541544583448"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_loss(Y_lin_train,forward_lin(X_lin_train,W_lin,b_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to compute the gradients, note that they are actually the same for both linear and logistic regression:\n",
    "$$\\frac{\\partial{J}}{\\partial{W}} =  \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}(y^{(i)}_{pred} - y^{(i)})$$\n",
    "$$\\frac{\\partial{J}}{\\partial{b}} =  \\frac{1}{m} \\sum_{i=1}^{m}(y^{(i)}_{pred} - y^{(i)}) $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grads(X, Y, Y_pred):\n",
    "    dW = (1.0/(Y.shape[1]))*np.dot(Y_pred-Y,X.T)\n",
    "    db = np.mean((Y_pred-Y),axis=1,keepdims=True)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_lin(X, W, b, Y, alpha=1e-2, iterations=500):\n",
    "    MSE_losses = []\n",
    "    for i in range(iterations):\n",
    "        Y_pred = forward_lin(X, W, b)\n",
    "        MSE_losses.append(MSE_loss(Y,Y_pred))\n",
    "        if(i%50==0):\n",
    "            print(\"Iteration {}: Loss={}\".format(i, MSE_losses[i]))\n",
    "        dW, db = grads(X, Y, Y_pred)\n",
    "        W = W -  alpha*dW\n",
    "        b = b - alpha*db\n",
    "    plt.plot(range(iterations),MSE_losses)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    return W, b\n",
    "\n",
    "\n",
    "def gradient_descent_log(X, W, b, Y, alpha=3e-2, iterations=1000):\n",
    "    log_losses = []\n",
    "    for i in range(iterations):\n",
    "        Y_pred = forward_log(X, W, b)\n",
    "        log_losses.append(log_loss(Y, Y_pred))\n",
    "        if(i%50==0):\n",
    "            print(\"Iteration {}: Loss={}\".format(i, log_losses[i]))\n",
    "        dW, db = grads(X, Y, Y_pred)\n",
    "        W = W -  alpha*dW\n",
    "        b = b - alpha*db\n",
    "    #plot the learning curve\n",
    "    plt.plot(range(iterations),log_losses)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run gradient descent on our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss=342.3541544583448\n",
      "Iteration 50: Loss=121.93439767824898\n",
      "Iteration 100: Loss=53.846512077548276\n",
      "Iteration 150: Loss=29.795968220984943\n",
      "Iteration 200: Loss=20.860325290303052\n",
      "Iteration 250: Loss=17.39177527472829\n",
      "Iteration 300: Loss=15.969941733782955\n",
      "Iteration 350: Loss=15.3389109971772\n",
      "Iteration 400: Loss=15.025940377382025\n",
      "Iteration 450: Loss=14.848681468122702\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104786ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_lin, b_lin = gradient_descent_lin(X_lin_train, W_lin, b_lin, Y_lin_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss=3.6538891900624355\n",
      "Iteration 50: Loss=0.6978207345650701\n",
      "Iteration 100: Loss=0.36665946810803884\n",
      "Iteration 150: Loss=0.2534189467137447\n",
      "Iteration 200: Loss=0.2014255167001032\n",
      "Iteration 250: Loss=nan\n",
      "Iteration 300: Loss=nan\n",
      "Iteration 350: Loss=nan\n",
      "Iteration 400: Loss=nan\n",
      "Iteration 450: Loss=nan\n",
      "Iteration 500: Loss=nan\n",
      "Iteration 550: Loss=nan\n",
      "Iteration 600: Loss=nan\n",
      "Iteration 650: Loss=nan\n",
      "Iteration 700: Loss=nan\n",
      "Iteration 750: Loss=nan\n",
      "Iteration 800: Loss=nan\n",
      "Iteration 850: Loss=nan\n",
      "Iteration 900: Loss=nan\n",
      "Iteration 950: Loss=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl0HOWZ7/Hv063WLlmyJW+Sd5vVIdjWsAUSIJkESA5kYQhZyQwzDhkyZJl77iSTO7kJ98y5yczNhCRkMiEhgTAEkoEMIQxZIIRhNwjHKwbbGIzlVd60Ly3puX9U2chCarVllUpS/z7n9Omq6re7n5e2/aOq3nrL3B0REZGhJOIuQERExjcFhYiIZKSgEBGRjBQUIiKSkYJCREQyUlCIiEhGCgoREclIQSEiIhkpKEREJKO8uAs4XlVVVT5//vy4yxARmVCef/75/e5ePZL3TrigmD9/PvX19XGXISIyoZjZ9pG+V4eeREQkIwWFiIhkpKAQEZGMFBQiIpKRgkJERDJSUIiISEYKChERyShnguLFPc38029epKk9HXcpIiITSs4ExWsH2vnXR19m+8G2uEsREZlQciYoZlcUAbDrcEfMlYiITCw5ExS1lUFQNBxSUIiIHI+cCYopRSmK85PsOtwZdykiIhNKzgSFmVFTUaRDTyIixymyoDCzQjN71szWmtlGM/vqIG0+YWaNZrYmfPxlVPVAcJ5ip4JCROS4RDnNeBdwsbu3mlkKeMLMfu3uzwxo9zN3/3SEdRw1u6KIDTubxuKrREQmjcj2KDzQGq6mwodH9X3ZqK0s4kBbNx3dvXGWISIyoUR6jsLMkma2BtgHPOTuqwZp9gEzW2dm95jZnCjrmV1RCMCuJh1+EhHJVqRB4e697n4mUAucZWZLBzT5FTDf3c8AHgZuH+xzzGylmdWbWX1jY+OI66mpKAZgp4bIiohkbUxGPbn7YeBR4JIB2w+4e1e4+gNgxRDvv8Xd69y9rrp6RLd8BfrtUeiEtohI1qIc9VRtZhXhchHwDuDFAW1m9Vu9HNgUVT0AM8sLSZiCQkTkeEQ56mkWcLuZJQkC6efu/oCZ3QjUu/v9wA1mdjnQAxwEPhFhPeQlE8wsL6RBQSEikrXIgsLd1wHLBtn+5X7LXwS+GFUNg5mti+5ERI5LzlyZfURNpS66ExE5HjkXFLMritjT1ElvX6yXdIiITBg5FxQ1FUWke539rV3DNxYRkdwMCtB04yIi2cq5oNANjEREjk8OBkVw0Z1OaIuIZCfngqKsMEV5YZ72KEREspRzQQFQU1ms+Z5ERLKUk0FRW1nEjkPtcZchIjIh5GRQzJ1azI6DHbjrWgoRkeHkZFDMqSyiI93L/tbuuEsRERn3cjIo5k4L7kuhw08iIsPLyaCYUxkGxUEFhYjIcHIyKGoVFCIiWcvJoCjKT1JdVsBrCgoRkWHlZFBAMPJJQSEiMrycDoodB3XRnYjIcHI2KOZUFrG7qYN0b1/cpYiIjGu5GxRTi+lzzSIrIjKcnA4KQOcpRESGEVlQmFmhmT1rZmvNbKOZfXWQNgVm9jMz22pmq8xsflT1DDR36pEhstqjEBHJJMo9ii7gYnd/M3AmcImZnTOgzbXAIXdfDHwT+HqE9RxjRnkhqaRpj0JEZBiRBYUHWsPVVPgYOAvfFcDt4fI9wNvNzKKqqb9kwqitLNY0HiIiw4j0HIWZJc1sDbAPeMjdVw1oUgPsAHD3HqAJmDbI56w0s3ozq29sbBy1+mori3R1tojIMCINCnfvdfczgVrgLDNbOqDJYHsPb5j7291vcfc6d6+rrq4etfqCaykUFCIimYzJqCd3Pww8Clwy4KUGYA6AmeUBU4CDY1ETBCOfDrWnaelMj9VXiohMOFGOeqo2s4pwuQh4B/DigGb3A9eEy1cCj/gY3k1II59ERIYX5R7FLOAPZrYOeI7gHMUDZnajmV0etrkVmGZmW4HPA1+IsJ43OBIUrx5oG8uvFRGZUPKi+mB3XwcsG2T7l/stdwJ/FlUNw1lQVQLAK/sVFCIiQ8nZK7MBSgrymFFeoKAQEckgp4MCgr0KBYWIyNAUFFWlCgoRkQxyPigWVpVwsK2bpnYNkRURGUzOB8X8Iye0NfJJRGRQOR8Ur498ah2mpYhIbsr5oJg7tZiEwSuN2qMQERlMzgdFfl6COVOL2aYT2iIig8r5oAANkRURyURBwetBMYbTTImITBgKCoIhsu3dvexr6Yq7FBGRcUdBQXDRHcA2ndAWEXkDBQWwoFqTA4qIDEVBAcwqL6QgL6FrKUREBqGgABIJ08gnEZEhKChCC6pKeFnnKERE3kBBEVoyo4ztB9roTPfGXYqIyLiioAidNKOUPoeXG3WeQkSkPwVF6OQZZQBs3tsScyUiIuNLZEFhZnPM7A9mtsnMNprZZwZpc6GZNZnZmvDx5cE+ayzMryohlTQ279UehYhIf3kRfnYP8LfuvtrMyoDnzewhd39hQLvH3f09EdaRlVQywcKqUjbv0R6FiEh/ke1RuPtud18dLrcAm4CaqL5vNCyZUcrmfQoKEZH+xuQchZnNB5YBqwZ5+VwzW2tmvzaz08einqGcPKOMHQc7aOvqibMMEZFxJfKgMLNS4F7gs+7ePODl1cA8d38z8B3gviE+Y6WZ1ZtZfWNjY2S1LglPaG/dp/MUIiJHRBoUZpYiCIk73f0XA19392Z3bw2XHwRSZlY1SLtb3L3O3euqq6sjq/ekGcHkgC9p5JOIyFFRjnoy4FZgk7v/yxBtZobtMLOzwnoORFXTcOZNKyE/L8EWBYWIyFFRjnp6C/AxYL2ZrQm3/T0wF8Dd/w24EviUmfUAHcDVHuPdg5IJY3F1qYbIioj0E1lQuPsTgA3T5mbg5qhqGImTZ5bxzLbYdmpERMYdXZk9wJIZpexu6qS5Mx13KSIi44KCYoCTpgcjn3SeQkQkoKAY4OSZQVBs2q2gEBEBBcUb1FYWMaUoxcZdTXGXIiIyLigoBjAzltaUs36ngkJEBBQUg1paM4WX9rTQ3dMXdykiIrFTUAxi6ewppHtd96YQEUFBMag31UwBYIMOP4mIKCgGM3dqMWUFeTpPISKCgmJQiYRxek05G3YNnOxWRCT3KCiGsHT2FDbtbibdqxPaIpLbFBRDeFPtFLp7+nRvChHJeQqKIZw+OzihrfMUIpLrFBRDWFhVQkl+ko0KChHJcQqKISQSxmmzdYW2iIiCIoMzaivYuKtZV2iLSE5TUGSwYl4lXT19miBQRHKagiKDFfMqAXh++6GYKxERiY+CIoMZ5YXUVhZR/6qCQkRyV1ZBYWaLzKwgXL7QzG4ws4poSxsf6uZVUr/9EO4edykiIrHIdo/iXqDXzBYDtwILgJ9meoOZzTGzP5jZJjPbaGafGaSNmdm3zWyrma0zs+XH3YOIrZg/lf2tXbx2sD3uUkREYpFtUPS5ew/wPuAmd/8cMGuY9/QAf+vupwLnANeb2WkD2lwKLAkfK4HvZV35GKnTeQoRyXHZBkXazD4EXAM8EG5LZXqDu+9299XhcguwCagZ0OwK4CceeAaoMLPhAmhMnTSjjLKCPOoVFCKSo7INij8HzgX+0d1fMbMFwL9n+yVmNh9YBqwa8FINsKPfegNvDBPMbKWZ1ZtZfWNjY7ZfOyqSCWPZvEqe1wltEclRWQWFu7/g7je4+11mVgmUufvXsnmvmZUSnOP4rLsPnLfbBvu6Qb7/Fnevc/e66urqbL52VNXNq2TzvhaaOtJj/t0iInHLdtTTo2ZWbmZTgbXAj83sX7J4X4ogJO50918M0qQBmNNvvRbYlU1NY6luXiXusPo17VWISO7J9tDTlHBv4P3Aj919BfCOTG8wMyMYIbXJ3YcKlfuBj4ejn84Bmtx9d5Y1jZkz51aQlzBWbTsYdykiImMuL9t24Unmq4AvZfmetwAfA9ab2Zpw298DcwHc/d+AB4HLgK1AO8G5kHGnOD+P5XMreWJrI3BK3OWIiIypbIPiRuC3wJPu/pyZLQS2ZHqDuz/B4Ocg+rdx4Posa4jV+Uuq+ObDmznY1s3Ukvy4yxERGTPZnsz+D3c/w90/Fa5vc/cPRFva+HL+kirc4cmt++MuRURkTGV7MrvWzP7TzPaZ2V4zu9fMaqMubjw5o2YK5YV5PLFFQSEiuSXbk9k/JjjxPJvgOodfhdtyRl4ywXmLqnhi637N+yQiOSXboKh29x+7e0/4uA0Y+wsaYnb+kip2Hu5g2/62uEsRERkz2QbFfjP7qJklw8dHgQNRFjYeXbCkCkCHn0Qkp2QbFH9BMDR2D7AbuJJxOpQ1SvOmlTB3ajGPKyhEJIdkO+rpNXe/3N2r3X26u7+X4OK7nHP+kiqe2XZA99EWkZxxIne4+/yoVTGBvOPU6bR29fDUy9qrEJHccCJBkfFiusnqvEVVlBbk8ZsNe+IuRURkTJxIUOTkGNHCVJKLTpnO717YS29fTv4nEJEckzEozKzFzJoHebQQXFORky5dOpODbd0896omCRSRyS9jULh7mbuXD/Ioc/ds54madN52UjUFeQkdfhKRnHAih55yVklBHm89qZrfbNhDnw4/icgkp6AYoUuXzmRPcydrGw7HXYqISKQUFCP09lNmkJcwHlw/7u6zJCIyqhQUIzSlOMVFp0znvjW76OnVxXciMnkpKE7AlStqaWzp0pQeIjKpKShOwEUnT2dqST73PN8QdykiIpFRUJyA/LwEV5w5m4de2Mvh9u64yxERiURkQWFmPwrviLdhiNcvNLMmM1sTPr4cVS1RunJFLd29ffxq7a64SxERiUSUexS3AZcM0+Zxdz8zfNwYYS2ROX32FE6dVa7DTyIyaUUWFO7+GJATc1xcuaKWtQ1NbNzVFHcpIiKjLu5zFOea2Voz+7WZnR5zLSN25fJailJJbnvy1bhLEREZdXEGxWpgnru/GfgOcN9QDc1spZnVm1l9Y2PjmBWYrSnFKd6/vIZfrt3FgdauuMsRERlVsQWFuze7e2u4/CCQMrOqIdre4u517l5XXV09pnVm6xPnzae7p4+7nn0t7lJEREZVbEFhZjPNzMLls8JaDsRVz4laMqOMC5ZUcccz20nrSm0RmUSiHB57F/A0cLKZNZjZtWZ2nZldFza5EthgZmuBbwNXu/uEnor1z98yn73NXZp+XEQmlcjuKeHuHxrm9ZuBm6P6/jhceNJ0FlSV8P3HXuY9Z8wi3GESEZnQ4h71NKkkEsanLlzEhp3NPPLivrjLEREZFQqKUfa+ZTXMmVrEt3+/hQl+JE1EBFBQjLpUMsH1Fy5mbUMT/715/A3lFRE5XgqKCLx/eS01FUV8S3sVIjIJKCgikJ+X4K8vWsQfXzuscxUiMuEpKCJyVd0cFlaX8I8PbtJ1FSIyoSkoIpJKJvjSZaeyrbGNO5/ZHnc5IiIjpqCI0MWnTOf8xVXc9PstNLWn4y5HRGREFBQRMjO+9O5TaepI882HN8ddjojIiCgoInbqrHI+fNZcfvL0q6xrOBx3OSIix01BMQb+7tJTqCot4O/uXa8T2yIy4SgoxkB5YYr/896lbNrdzA8e3xZ3OSIix0VBMUbedfpMLl06k5se3sLWfa1xlyMikjUFxRj66uWnU5yf5DN3/5Gunt64yxERyYqCYgxNLy/k6x84g427mvnG7zQKSkQmBgXFGHvX6TP5yNlzueWxbTy+RZMGisj4p6CIwf9692ksnl7K5362ht1NHXGXIyKSkYIiBkX5Sb73keV0dPdy3b+v1vkKERnXFBQxWTKjjG9c9WbW7jjMl+/bqOnIRWTcUlDE6JKls7j+okX8rH4Htz31atzliIgMKrKgMLMfmdk+M9swxOtmZt82s61mts7MlkdVy3j2+T89mT89bQY3PvACv924J+5yRETeIMo9ituASzK8fimwJHysBL4XYS3jVjJhfPvqZZxRW8ENd/2R1a8dirskEZFjRBYU7v4YcDBDkyuAn3jgGaDCzGZFVc94VpSf5NZr6phRXsi1tz3H5r0tcZckInJUnOcoaoAd/dYbwm1vYGYrzazezOobGyfntQdVpQX85C/OIpVM8JEfruKV/W1xlyQiAsQbFDbItkGH/rj7Le5e5+511dXVEZcVn/lVJfz0r86mr8/5yA+eYcfB9rhLEhGJNSgagDn91muBXTHVMm4snl7GHdeeTVt3L1d9/2lNICgisYszKO4HPh6OfjoHaHL33THWM26cNrucu1eeQ7rXuer7T7NhZ1PcJYlIDotyeOxdwNPAyWbWYGbXmtl1ZnZd2ORBYBuwFfgB8NdR1TIRnTqrnHuuO5eiVJIP3fIMz76SaVyAiEh0bKJdEVxXV+f19fVxlzFmdh3u4KO3rmLnoQ6+dfWZXLI0JweGicgJMrPn3b1uJO/Vldnj3OyKIv7jk+dy6qxyrvv31Xzn91s03YeIjCkFxQQwrbSAu1eew3vPnM03HtrMZ+5eQ2daEwmKyNjIi7sAyU5hKsk3P3gmJ80s459/+xLbD7Tx3Y8sp7ayOO7SRGSS0x7FBGJm/PWFi/n+R1ewrbGNy771uOaHEpHIKSgmoHeePpP/uuEC5leV8Mk7nud//3KDDkWJSGQUFBPU3GnF3HPdeVx7/gJuf3o77/vXp3hhV3PcZYnIJKSgmMDy8xL8w3tO49Zr6mhs6eLym5/gpoc3093TF3dpIjKJKCgmgbefOoOHPvdW3nPGLG56eAuX3/wE6xt0NbeIjA4FxSRRWZLPTVcv45aPreBAWzdXfPcJ/uG+DTS1p+MuTUQmOAXFJPPO02fy8OffxsfPnc+dq7Zz0Tce5WfPvUZfny7SE5GRUVBMQlOKUnzl8tN54G8uYFF1CX9373ou/+4TPLFlf9ylicgEpKCYxE6bXc7PP3kuN33wTA61pfnorav42K2rNButiBwXTQqYI7p6ernj6e3c/IetHG5Pc+nSmVx/0WKW1kyJuzQRGQMnMimggiLHNHem+cFj27jtyVdp6erh4lOmc/1Fi1kxrzLu0kQkQgoKOW5NHWnuePpVbn3iFQ61pzlv0TQ++bZFXLC4ikRisLvUishEpqCQEWvr6uGnq17jlse30djSxcKqEq45bz4fWFFLaYHmjBSZLBQUcsK6e/p4cP1ubnvqVdbsOExpQR5Xrqjlo+fMZfH0srjLE5ETpKCQUbVmx2Fuf+pVHli3i3Svs2xuBVfVzeE9Z8yirDAVd3kiMgIKColEY0sX9/1xJz+v38GWfa0UphJctnQW719eyzkLp5KX1OhqkYli3AaFmV0CfAtIAj90968NeP0TwD8DO8NNN7v7DzN9poJi7Lk7axua+Hn9Dn61ZhctXT1MK8nnkqUzefcZszh7wTSSOgEuMq6Ny6AwsySwGfhToAF4DviQu7/Qr80ngDp3/3S2n6ugiFdnupdHX9rHA+t28/tN++hI91JVWsBlb5rJZW+aRd28Su1piIxDJxIUUQ5rOQvY6u7bAMzsbuAK4IWM75JxrTCV5JKls7hk6Sw6unt55MV9/Nf6Xfy8fgc/eXo75YV5vO3k6bz9lOm87aRqKkvy4y5ZRE5QlEFRA+zot94AnD1Iuw+Y2VsJ9j4+5+47Bmkj41BRfpJ3nzGLd58xi7auHh7b3MgjL+7jDy/t41drd5EwWD63kotOmc5bl1Rz2uxyHaISmYCiPPT0Z8C73P0vw/WPAWe5+9/0azMNaHX3LjO7DrjK3S8e5LNWAisB5s6du2L79u2R1Cyjo6/PWb+zid+/uI9HXtzLhp3BnfemFKU4d+E03rJ4GucuqmJRdQlmCg6RsTBez1GcC3zF3d8Vrn8RwN3/7xDtk8BBd884+ZDOUUw8+5o7eerlAzy5dT9PvXyAnYc7AJhZXsjZC6dSN6+S5fMqOWWm9jhEojJez1E8BywxswUEo5quBj7cv4GZzXL33eHq5cCmCOuRmEwvL+S9y2p477Ia3J3XDrbz5NYDPPlyEBy/XLMLgJL8JMvmVrJiXvBYNrdC122IjAORBYW795jZp4HfEgyP/ZG7bzSzG4F6d78fuMHMLgd6gIPAJ6KqR8YHM2PetBLmTSvhw2fPxd1pONTB89sPUb/9IM9vP8x3HtlCn4MZLKou5U01U1haM4U31Uzh9NnllGhqEZExpQvuZNxp6UyzZsdhnt9+iPUNTazf2cS+li4gCI+FVSVHw+PkmWWcPLOM6tICne8QyWC8HnoSGZGywhQXLKnmgiXVR7fta+5kw64m1jc0s35nE89sO8h94SErgMriFCfNKDsaHCfPKGPJjDKmFOnQlciJUlDIhDC9vJCLywu5+JQZR7cdaO3ipb0tbN7Twkt7W3lpTzO/WL2T1q6eo21mlheysLqEBVXHPuZMLSalCwNFsqKgkAlrWmkB55UWcN6iqqPb3J1dTZ28tKeZl/a0smVvC68caOO/1u/mcHv6aLtkwpg7tfhocMyvKmFOZRG1lcXUVhZRmErG0SWRcUlBIZOKmVFTUURNRdExex8Ah9q6eeVAG680tvHK/uCxbX8bT728n8503zFtq8sKqO0XHEeW51QWMbtCQSK5RUEhOaOyJJ/KknyWzz32tq99fc6+li4aDrXTcKiDHQeD54bD7axrOMyv1++mp+/YQR9VpfnMKC9kZnkhM6cEzzOm9FufUkhZQZ5OsMukoKCQnJdI2NF/3Ovmv/H13j5nb3NnEB6H2tlxsIM9zR3sbupk5+EOVr92iEP9DmsdUZyfDAIkDI/qsgKqSvOZVlJAVbhcXVpAZUm+zpfIuKagEBlGMmHMrggOOZ21YOqgbTrTvexr7mJPc2fwaOpgT1MXe8P1Z185yP7WLrp6+gZ9f2VxiqrSAqaV5lNVWkBVaQHVZQVMC/eCKovzqShOUVGcorJYwSJjS0EhMgoKU0nmTitm7rTiIdu4O61dPRxo7WZ/a1f4eH35yPaNu5rZ39pFS2fPkJ9VWpB3NDSCAMmnst/zke1TilKUFaYoL8qjvDBFQV5Ch8PkuCkoRMaImVFWGPzDPb+qZNj2neleDrR1c6itm8PtaQ61d3O4/chymsPt3Rxq7+ZQe5odB9s51J6muTNNpmto85MJygrzKC9KBc+FA54Hbg/XSwvyKCnIoyQ/j8KUwibXKChExqnCVPLoCK5s9fY5TR2vh0pzRw/NnWmaO3to7kjT0hmstxxdT7OnuZOWzjTNHT10pHuH/Y6EQUl+EBzFBUlKC/Iozj/yfCRQksFzQZLi/Lxj24SvF6aSFOUnKUoFy5oQcvxSUIhMIsmEMbUkn6kjvGFUurePls6eo8HR0hnspbR29dLe3UNrVw/tXb3Bc3cPbV29tHX30NbVw67DneFy0La9e/jQ6S8/maAwlTgmPI5ZProtQdGR9fwkhXnHtitMJSjIS5Kfl6AgL/jM/GSSglSwHmxXMB0PBYWIHJVKJk4oaPrr7XM60r20dfWEj9dDpa27l87064+O7j46ji730pHuPbreme6luTNNR3cvnemgXUd3L509vRkPsw0nL2HHBEdBKkF+MhEGSrLfa8cGT//l/LzgPamkkcpLkEoeWX992zHryeA9eYnXl495LZkgMQ4DTEEhIpFIJozSguCwUxTcna6eviBcwvBo7+6lq6eP7p4+unr6LwfrR5fTA9aPWX79/a1dPXSl++ju7aMrfezndfcOPoLtRCUTdkxwpJIJUnnB+of+ZC5/9daFkXxvJgoKEZmQzCw81JSkIobv7+tz0n19pHuddE8f6d4gPNK9HiyH246u9/aF7fqt99t2dD18z5H39/RrX11WEENPFRQiIiOSSBgFiSQFeUA8/36PGV21IyIiGSkoREQkIwWFiIhkpKAQEZGMIg0KM7vEzF4ys61m9oVBXi8ws5+Fr68ys/lR1iMiIscvsqAwsyTwXeBS4DTgQ2Z22oBm1wKH3H0x8E3g61HVIyIiIxPlHsVZwFZ33+bu3cDdwBUD2lwB3B4u3wO83TTbmIjIuBJlUNQAO/qtN4TbBm3j7j1AEzAtwppEROQ4RXnB3WB7BgNnZsmmDWa2ElgZrraa2UsjrKkK2D/C904G6n/u9j+X+w7qfxUwb6RvjjIoGoA5/dZrgV1DtGkwszxgCnBw4Ae5+y3ALSdakJnVu3vdiX7ORKX+527/c7nvoP6H/Z8/0vdHeejpOWCJmS0ws3zgauD+AW3uB64Jl68EHnE/kfkgRURktEW2R+HuPWb2aeC3QBL4kbtvNLMbgXp3vx+4FbjDzLYS7ElcHVU9IiIyMpFOCujuDwIPDtj25X7LncCfRVnDACd8+GqCU/9zVy73HdT/E+q/6UiPiIhkoik8REQko5wJiuGmE5mMzOxVM1tvZmvMrD7cNtXMHjKzLeFzZdx1jgYz+5GZ7TOzDf22DdpXC3w7/LOwzsyWx1f56Bii/18xs53h77/GzC7r99oXw/6/ZGbviqfq0WFmc8zsD2a2ycw2mtlnwu058ftn6P/o/f7uPukfBCfTXwYWAvnAWuC0uOsag36/ClQN2PZPwBfC5S8AX4+7zlHq61uB5cCG4foKXAb8muA6nnOAVXHXH1H/vwL8j0Hanhb+HSgAFoR/N5Jx9+EE+j4LWB4ulwGbwz7mxO+fof+j9vvnyh5FNtOJ5Ir+06bcDrw3xlpGjbs/xhuvwRmqr1cAP/HAM0CFmc0am0qjMUT/h3IFcLe7d7n7K8BWgr8jE5K773b31eFyC7CJYNaHnPj9M/R/KMf9++dKUGQznchk5MDvzOz58Op2gBnuvhuCP2DA9Niqi95Qfc2lPw+fDg+v/KjfYcZJ2/9wBuplwCpy8Pcf0H8Ypd8/V4Iiq6lCJqG3uPtyghl8rzezt8Zd0DiRK38evgcsAs4EdgPfCLdPyv6bWSlwL/BZd2/O1HSQbZOx/6P2++dKUGQzncik4+67wud9wH8S7F7uPbKbHT7vi6/CyA3V15z48+Due9291937gB/w+uGFSdd/M0sR/CN5p7v/ItycM7//YP0fzd8/V4Iim+lEJhUzKzGzsiPLwDuBDRw7bco1wC/jqXBMDNXX+4GPh6NfzgGajhyimEwGHHd/H8HvD0H/r7bgxmELgCXAs2Nd32gJb01wK7DJ3f9tdRFAAAAC80lEQVSl30s58fsP1f9R/f3jPmM/hiMDLiMYDfAy8KW46xmD/i4kGNmwFth4pM8E07j/HtgSPk+Nu9ZR6u9dBLvXaYL/Y7p2qL4S7Hp/N/yzsB6oi7v+iPp/R9i/deE/DrP6tf9S2P+XgEvjrv8E+34+waGTdcCa8HFZrvz+Gfo/ar+/rswWEZGMcuXQk4iIjJCCQkREMlJQiIhIRgoKERHJSEEhIiIZKSgk55hZa/g838w+PMqf/fcD1p8azc8XiYOCQnLZfOC4gsLMksM0OSYo3P2846xJZNxRUEgu+xpwQThX/+fMLGlm/2xmz4UTqX0SwMwuDOf7/ynBBUyY2X3hZIsbj0y4aGZfA4rCz7sz3HZk78XCz95gwT1CPtjvsx81s3vM7EUzuzO80hYz+5qZvRDW8v/G/L+OSCjSe2aLjHNfIJiv/z0A4T/4Te7+J2ZWADxpZr8L254FLPVgWmaAv3D3g2ZWBDxnZve6+xfM7NPufuYg3/V+gsnZ3gxUhe95LHxtGXA6wXw7TwJvMbMXCKZdOMXd3cwqRr33IlnSHoXI695JMAfQGoJpmqcRzIMD8Gy/kAC4wczWAs8QTLC2hMzOB+7yYJK2vcB/A3/S77MbPJi8bQ3BIbFmoBP4oZm9H2g/4d6JjJCCQuR1BvyNu58ZPha4+5E9irajjcwuBN4BnOvubwb+CBRm8dlD6eq33AvkuXsPwV7MvQQ33PnNcfVEZBQpKCSXtRDcOvKI3wKfCqdsxsxOCmfeHWgKcMjd283sFILbaR6RPvL+AR4DPhieB6kmuHXpkDN2hvcWmOLuDwKfJThsJRILnaOQXLYO6AkPId0GfIvgsM/q8IRyI4PfKvY3wHVmto5g9s1n+r12C7DOzFa7+0f6bf9P4FyC2Xwd+J/uvicMmsGUAb80s0KCvZHPjayLIidOs8eKiEhGOvQkIiIZKShERCQjBYWIiGSkoBARkYwUFCIikpGCQkREMlJQiIhIRgoKERHJ6P8D56Z/h7KLTPsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109986a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_log, b_log = gradient_descent_log(X_log_train, W_log,b_log, Y_log_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can test our trained algorithms on the test set:\n",
    "For the logistic regression algorithm, we can measure its performance with accuracy, for linear regression we use MSE.\n",
    "**EXTENSION** Look at the F1 metric instead of accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.720477887308476"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_loss(Y_lin_test, forward_lin(X_lin_test,W_lin,b_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y,Y_pred):\n",
    "    return np.mean(np.abs(np.round(Y_pred)-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043596730245231606"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_log_test, forward_log(X_log_test,W_log,b_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not a good metric when the dataset is skewed, instead we look at another metric called the F1 Score (ranges between 0 and 1) - higher is better. Using this, it turns out our logistic regression model's performance is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Score(AL, Y):\n",
    "    prediction = (AL >= (np.ones_like(AL)/2))\n",
    "    \n",
    "    truth_pos = (Y == np.ones_like(Y))\n",
    "    truth_neg = (Y == np.zeros_like(Y))\n",
    "    pred_pos = (prediction == np.ones_like(prediction))\n",
    "    pred_neg = (prediction == np.zeros_like(prediction))\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(truth_pos,pred_pos))\n",
    "    if true_pos == 0: #This prevents an undefined computation since precision=recall=0 \n",
    "        return 0\n",
    "    false_pos =np.sum(np.logical_and(truth_neg,pred_pos))\n",
    "    false_neg =np.sum(np.logical_and(truth_pos,pred_neg))\n",
    "    true_neg =np.sum(np.logical_and(truth_neg,pred_neg))\n",
    "\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = (true_pos)/(true_pos + false_neg)\n",
    "    F1_score = 2*(recall*precision) /(recall + precision)\n",
    "    return F1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416058394160584"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_Score(forward_log(X_log_test,W_log,b_log),Y_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
