{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks\n",
    "\n",
    "This Jupyter notebook accompanies the blog post on Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the dependencies - **numpy**, the python linear algebra library, **pandas** to load and preprocess the input data and **matplotlib** for visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be using the same datasets as with the linear and logistic regression models - to provide a comparison. The code for pre-processing the data is as follows, go to the <a href=\"https://github.com/mukul-rathi/blogPost-tutorials/blob/master/LinearLogisticRegression/LinearLogisticRegression.ipynb\"> Linear/Logistic Regression notebook </a> for a more detailed explanation of the code.\n",
    "\n",
    "<p> First, the house dataset - this is the dataset we used for linear regression. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_dataset = pd.read_csv(\"../LinearLogisticRegression/boston-housing-dataset/train.csv\")\n",
    "house_dataset.drop(\"ID\", axis=1, inplace=True)\n",
    "house_dataset = house_dataset.reindex(np.random.permutation(house_dataset.index))\n",
    "#normalise the input features - this ensures they are all in the same range 0-1. \n",
    "house_dataset.loc[:, house_dataset.columns!=\"medv\"] -= house_dataset.loc[:, house_dataset.columns!=\"medv\"].mean()\n",
    "house_dataset.loc[:, house_dataset.columns!=\"medv\"] /= house_dataset.loc[:, house_dataset.columns!=\"medv\"].std()\n",
    "\n",
    "#transpose to get correct dimensions\n",
    "X_lin_train = house_dataset.loc[:house_dataset.shape[0]*4//5, house_dataset.columns!=\"medv\"].as_matrix().T \n",
    "Y_lin_train = house_dataset.loc[:house_dataset.shape[0]*4//5, [\"medv\"]].as_matrix().T\n",
    "\n",
    "X_lin_test = house_dataset.loc[house_dataset.shape[0]*4//5:, house_dataset.columns!=\"medv\"].as_matrix().T \n",
    "Y_lin_test = house_dataset.loc[house_dataset.shape[0]*4//5:, [\"medv\"]].as_matrix().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the breast cancer dataset - used for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset = pd.read_csv(\"../LinearLogisticRegression/breast-cancer-dataset/data.csv\")\n",
    "cancer_dataset.drop([\"id\",'Unnamed: 32'], axis=1, inplace=True)\n",
    "cancer_dataset[\"diagnosis\"] = cancer_dataset[\"diagnosis\"].apply(lambda x: 1 if (x==\"M\") else 0)\n",
    "#shuffle data\n",
    "cancer_dataset = cancer_dataset.reindex(np.random.permutation(cancer_dataset.index))\n",
    "\n",
    "#normalise the input features - this ensures they are all in the same range 0-1. \n",
    "cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"] -= cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"].mean()\n",
    "cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"] /= cancer_dataset.loc[:, cancer_dataset.columns!=\"diagnosis\"].std()\n",
    "\n",
    "X_log_train = cancer_dataset.loc[:cancer_dataset.shape[0]*4//5, cancer_dataset.columns!=\"diagnosis\"].as_matrix().T \n",
    "Y_log_train = cancer_dataset.loc[:cancer_dataset.shape[0]*4//5, [\"diagnosis\"]].as_matrix().T \n",
    "\n",
    "X_log_test = cancer_dataset.loc[cancer_dataset.shape[0]*4//5:, cancer_dataset.columns!=\"diagnosis\"].as_matrix().T \n",
    "Y_log_test = cancer_dataset.loc[cancer_dataset.shape[0]*4//5:, [\"diagnosis\"]].as_matrix().T \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the neural network:\n",
    "\n",
    "Having preprocessed our data into matrices, it is now time to create the feedforward neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to initialise parameters: the weights and biases for each layer.\n",
    "\n",
    "The weights for layer *$l$* are stored in *$ W^{(l)}$*, a *$n_l$ x $n_{(l-1)}$* matrix, where *$n_l$* is the number of units in layer *$l$*. \n",
    "We  initialise the weights randomly from a Gaussian distribution ($\\mu=0, \\sigma =1$) to break symmetry, and multiply by 0.001 to ensure weights aren't too large.\n",
    "\n",
    "The biases for layer *$l$* are stored in *$ b^{(l)}$*, which is a *$n_l$ x 1* matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_parameters(layers_units):\n",
    "    parameters = {}            # create a dictionary containing the parameters\n",
    "    for l in range(1, len(layers_units)):\n",
    "        parameters['W' + str(l)] = 0.001* np.random.randn(layers_units[l],layers_units[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layers_units[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function $g(z)$ we will be using is the ReLU function $g(z) = max(0,z)$ in the hidden layers.\n",
    "\n",
    "<br> The only difference in the neural net between regression and classification is the final layer - whether we use the sigmoid function in the final layer, depending on whether we want to do regression or classification. \n",
    "\n",
    "NB: Although the ReLU function is technically non-differentiable when $z=0$, in practice we can set the derivative=0 at $z=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def relu(z, deriv = False):\n",
    "    if(deriv):\n",
    "        return z>0\n",
    "    else:\n",
    "        return np.multiply(z, z>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write the code for the forward propagation step.\n",
    "\n",
    "In each layer $l$ , we matrix multiply the output of the previous layer $A^{(l-1)}$  by a weight matrix $W^{(l)}$ and then add a bias term $b^{(l)}$. We then take the result $Z^{(l)}$ and apply the activation function $g(z)$ to it to get the output $A^{(l)}$. $L$ = number of layers.\n",
    "The equations are thus:\n",
    "$$Z^{(l)}=W^{(l)}A^{(l-1)}$$\n",
    "$$A^{(l)}=g(Z^{(l)})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters,linear):\n",
    "    cache = {}\n",
    "    L = len(parameters)//2 #final layer\n",
    "    cache[\"A0\"] = X #ease of notation since input = layer 0\n",
    "    for l in range(1, L):\n",
    "        cache['Z' + str(l)] = np.dot(parameters['W' + str(l)],cache['A' + str(l-1)]) + parameters['b' + str(l)]\n",
    "        cache['A' + str(l)] = relu(cache['Z' + str(l)])\n",
    "    #final layer\n",
    "    cache['Z' + str(L)] = np.dot(parameters['W' + str(L)],cache['A' + str(L-1)]) + parameters['b' + str(L)]\n",
    "    cache['A' + str(L)] =cache['Z' + str(L)] if linear else sigmoid(cache['Z' + str(L)])\n",
    "    return cache "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can compute the loss function - this is the objective function the neural network will aim to minimise during training:\n",
    "\n",
    "$m$ = number of training examples, $(x^{(i)},y^{(i)})$ is the $i^{th}$ training example.\n",
    "<br> For regression: \n",
    "$$ J(W^{(1)}, b^{(1)},...) = \\frac{1}{2m} \\sum_{i=1}^{m} (a^{(L) (i)} - y^{(i)})^2 $$\n",
    "\n",
    "\n",
    "For classification: \n",
    "\n",
    "$$J(W^{(1)}, b^{(1)},...) = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} y^{(i)}\\log\\left(a^{(L) (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{(L)(i)}\\right)Â $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(AL,Y, linear):\n",
    "    m = Y.shape[1]\n",
    "    if linear:\n",
    "        cost = (1/(2*m))*(np.sum(np.square(AL-Y)))\n",
    "    else:\n",
    "        cost = (-1/m)*( np.sum(np.multiply(Y,np.log(AL))) + np.sum(np.multiply((1-Y),np.log(1-AL))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will code the backpropagation algorithm. This will enable us to calculate the partial derivative of the cost function with respect to each of the weights and biases in each of the layers of the network. The equations can be derived using the multivariable chain rule and are the same for both regression and classification:\n",
    "$$\\frac{\\partial \\mathcal{J} }{\\partial Z^{(L)}} = A^{(L)} - Y$$ \n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{J} }{\\partial W^{(l)}} = \\frac{1}{m}\\frac{\\partial \\mathcal{J} }{\\partial Z^{(l)}} A^{(l-1) T} $$\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{J} }{\\partial b^{(l)}} = \\frac{1}{m} \\sum_{i = 1}^{m} \\frac{\\partial \\mathcal{J} }{\\partial Z^{(l)(i)}}$$\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{J} }{\\partial A^{(l-1)}} = W^{(l) T} \\frac{\\partial \\mathcal{J} }{\\partial Z^{(l)}} $$\n",
    "$$ \\frac{\\partial \\mathcal{J} }{\\partial Z^{(l-1)}} = \\frac{\\partial \\mathcal{J} }{\\partial A^{(l-1)}}*g^{'}(Z^{(l-1)})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(cache,Y,parameters):\n",
    "    L = len(parameters)//2 \n",
    "    m = Y.shape[1]\n",
    "    grads = {}\n",
    "    grads[\"dZ\" + str(L)]= cache[\"A\" + str(L)] - Y\n",
    "    grads[\"dW\" + str(L)]= (1/m)*np.dot(grads[\"dZ\" + str(L)],cache[\"A\" + str(L-1)].T) \n",
    "    grads[\"db\" + str(L)]= (1/m)*np.sum(grads[\"dZ\" + str(L)],axis=1,keepdims=True)\n",
    "    for l in range(L-1,0,-1):\n",
    "        grads[\"dA\" + str(l)]= np.dot(parameters[\"W\" + str(l+1)].T,grads[\"dZ\" + str(l+1)])\n",
    "        grads[\"dZ\" + str(l)]= np.multiply(grads[\"dA\" + str(l)], relu(cache[\"Z\" + str(l)], deriv = True))\n",
    "        grads[\"dW\" + str(l)]= (1/m)*np.dot(grads[\"dZ\" + str(l)],cache[\"A\" + str(l-1)].T) \n",
    "        grads[\"db\" + str(l)]= (1/m)*np.sum(grads[\"dZ\" + str(l)],axis=1,keepdims=True)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have an evaluation metric to see if the model is actually learning.\n",
    "\n",
    "For regression, we use Mean Squared Error.\n",
    "\n",
    "For classification, since the data is skewed, accuracy is not a good metric. So instead we will use the F1 score. The equation for F1 score is as follows:\n",
    "$$ Precision = \\frac{True \\space Positive}{True\\space Positive + False \\space Positive}$$\n",
    "    \n",
    "$$Recall = \\frac{True \\space Positive}{True\\space Positive + False \\space Negative} $$\n",
    "\n",
    "$$F1\\space Score = \\frac{2*Precision*Recall}{Precision + Recall} $$\n",
    "\n",
    "The F1 score returns a value between 0 and 1 and a higher score means the performance of the model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(AL, Y):\n",
    "    prediction = (AL >= (np.ones_like(AL)/2))\n",
    "    \n",
    "    truth_pos = (Y == np.ones_like(Y))\n",
    "    truth_neg = (Y == np.zeros_like(Y))\n",
    "    pred_pos = (prediction == np.ones_like(prediction))\n",
    "    pred_neg = (prediction == np.zeros_like(prediction))\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(truth_pos,pred_pos))\n",
    "    if true_pos == 0: #This prevents an undefined computation since precision=recall=0 \n",
    "        return 0\n",
    "    false_pos =np.sum(np.logical_and(truth_neg,pred_pos))\n",
    "    false_neg =np.sum(np.logical_and(truth_pos,pred_neg))\n",
    "    true_neg =np.sum(np.logical_and(truth_neg,pred_neg))\n",
    "\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = (true_pos)/(true_pos + false_neg)\n",
    "    F1_score = 2*(recall*precision) /(recall + precision)\n",
    "    return F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metric(AL, Y, linear):\n",
    "    if linear:\n",
    "        return cost_function(AL,Y,linear) #MSE for regression\n",
    "    else:\n",
    "        return F1_score(AL, Y) #F1 score for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's combine the functions created so far to create a model and train it using  gradient descent. \n",
    "\n",
    "The update equations for the parameters are as follows:\n",
    "$$ W^{(l)} = W^{(l)} - \\alpha \\frac{\\partial \\mathcal{J} }{\\partial W^{(l)}} $$\n",
    "\n",
    "$$ b^{(l)} = b^{(l)} - \\alpha \\frac{\\partial \\mathcal{J} }{\\partial b^{(l)}} $$\n",
    "\n",
    "where $\\alpha$ is the learning rate parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train,num_epochs,layers_units,learning_rate, linear):\n",
    "    train_costs = []\n",
    "    \n",
    "    parameters = initialise_parameters(layers_units)\n",
    "    L = len(layers_units)-1 \n",
    "    for epoch in range (num_epochs):\n",
    "        #perform one cycle of forward and backward propagation to get the partial derivatives w.r.t. the weights\n",
    "        #and biases. Calculate the cost - used to monitor training\n",
    "        cache = forward_propagation(X_train,parameters,linear)\n",
    "        cost = cost_function(cache[\"A\" + str(L)],Y_train,linear)\n",
    "        grads = backpropagation(cache,Y_train,parameters)\n",
    "\n",
    "        #update the parameters using gradient descent\n",
    "        for l in range(1,L+1):\n",
    "            parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"dW\" + str(l)]\n",
    "            parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"db\" + str(l)]\n",
    "\n",
    "        #periodically output an update on the current cost and performance on the dev set for visualisation\n",
    "        train_costs.append(cost)\n",
    "        if(epoch%(num_epochs//10)==0):\n",
    "            print(\"Training the model, epoch: \" + str(epoch+1))\n",
    "            print(\"Cost after epoch \" + str((epoch)) + \": \" + str(cost))\n",
    "    print(\"Training complete!\")\n",
    "    #return the trained parameters and the visualisation metrics\n",
    "    return parameters, train_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we visualise the training set error over the number of iterations. We then output the final value of the evaluation metric for training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_costs,parameters,X_train, Y_train, X_test, Y_test, linear):\n",
    "    #plot the graphs of training set error\n",
    "    plt.plot(np.squeeze(train_costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.title(\"Training Set Error\")\n",
    "    plt.show()\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    #For train and test sets, perform a step of forward propagation to obtain the trained model's \n",
    "    #predictions and evaluate this with an F1 score.\n",
    "    train_cache = forward_propagation(X_train,parameters,linear)\n",
    "    train_AL = train_cache[\"A\"+ str(L)]\n",
    "    if linear: \n",
    "         print(\"The train set MSE is: \"+str(evaluation_metric(train_AL,Y_train, linear)))\n",
    "    else:\n",
    "        print(\"The train set F1 score is: \"+str(evaluation_metric(train_AL,Y_train, linear)))\n",
    "    \n",
    "    test_cache = forward_propagation(X_test,parameters, linear)\n",
    "    test_AL = test_cache[\"A\"+ str(L)]\n",
    "    if linear:\n",
    "                print(\"The test set MSE is: \"+str(evaluation_metric(test_AL,Y_test, linear)))\n",
    "    else:\n",
    "        print(\"The test set F1 score is: \"+str(evaluation_metric(test_AL,Y_test, linear)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can write the overall function to run the neural network - this ensures it is easy to run subsequent models by packaging all the functions into one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, Y_train, X_test, Y_test, hyperparameters, linear=True):\n",
    "    num_epochs = hyperparameters[\"num_epochs\"]\n",
    "    layers_units = hyperparameters[\"layers_units\"]\n",
    "    learning_rate = hyperparameters[\"learning_rate\"]\n",
    "    \n",
    "    parameters, train_costs = train_model(X_train, Y_train ,num_epochs,layers_units,learning_rate,linear)         \n",
    "    evaluate_model(train_costs,parameters,X_train, Y_train, X_test, Y_test,linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters for the model\n",
    "def create_hyperparameters(X, num_epochs):\n",
    "    hyperparameters={}\n",
    "    hyperparameters[\"num_epochs\"] = num_epochs #number of passes through the training set\n",
    "    hyperparameters[\"layers_units\"] = [X.shape[0], 64, 64,32, 1] #layer 0 is the input layer\n",
    "    hyperparameters[\"learning_rate\"] = 1e-3\n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model, epoch: 1\n",
      "Cost after epoch 0: 317.1803170720049\n",
      "Training the model, epoch: 101\n",
      "Cost after epoch 100: 20.39806761100618\n",
      "Training the model, epoch: 201\n",
      "Cost after epoch 200: 7.032355284852191\n",
      "Training the model, epoch: 301\n",
      "Cost after epoch 300: 5.376387288679558\n",
      "Training the model, epoch: 401\n",
      "Cost after epoch 400: 4.366280149491956\n",
      "Training the model, epoch: 501\n",
      "Cost after epoch 500: 3.722877431000237\n",
      "Training the model, epoch: 601\n",
      "Cost after epoch 600: 3.325948906267952\n",
      "Training the model, epoch: 701\n",
      "Cost after epoch 700: 3.0425293025870928\n",
      "Training the model, epoch: 801\n",
      "Cost after epoch 800: 2.7836146928966983\n",
      "Training the model, epoch: 901\n",
      "Cost after epoch 900: 2.5920008899660942\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150baef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set MSE is: 2.47320001814079\n",
      "The test set MSE is: 12.144280011641133\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = create_hyperparameters(X_lin_train, 1000)\n",
    "run_model(X_lin_train, Y_lin_train, X_lin_test, Y_lin_test,hyperparameters, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model, epoch: 1\n",
      "Cost after epoch 0: 0.6931471805415712\n",
      "Training the model, epoch: 7001\n",
      "Cost after epoch 7000: 0.42260983689735593\n",
      "Training the model, epoch: 14001\n",
      "Cost after epoch 14000: 0.3875974239952056\n",
      "Training the model, epoch: 21001\n",
      "Cost after epoch 21000: 0.36185435291421825\n",
      "Training the model, epoch: 28001\n",
      "Cost after epoch 28000: 0.34686309512342506\n",
      "Training the model, epoch: 35001\n",
      "Cost after epoch 35000: 0.3333749820469602\n",
      "Training the model, epoch: 42001\n",
      "Cost after epoch 42000: 0.3225978118573446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model, epoch: 49001\n",
      "Cost after epoch 49000: nan\n",
      "Training the model, epoch: 56001\n",
      "Cost after epoch 56000: nan\n",
      "Training the model, epoch: 63001\n",
      "Cost after epoch 63000: nan\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150bab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set F1 score is: 0.9800796812749003\n",
      "The test set F1 score is: 0.925925925925926\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = create_hyperparameters(X_log_train,75000)\n",
    "run_model(X_log_train, Y_log_train, X_log_test, Y_log_test,hyperparameters, linear=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with the linear and logistic regression models it is clear that the neural network outperforms these two algorithms. \n",
    "\n",
    "**Performance on Test Sets:**\n",
    "\n",
    "    Linear Regression: MSE of 12.144280011641133 vs 24.35323181847871\n",
    "\n",
    "    Logistic Regression: F1 score of 0.925925925925926 vs 0.918918918918919\n",
    "\n",
    "However, what is interesting to note is that the neural net performs much worse on the test set compared to the training set - this is known as **overfitting**. \n",
    "\n",
    "In future blog posts, we will look at this issue, as well as looking at techniques that can improve gradient descent for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
